{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import matplotlib as mp;\n",
    "import matplotlib.pyplot as plt;\n",
    "import matplotlib.patches as patches;\n",
    "import pandas as pd;\n",
    "import math;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers several alternatives for easy evaluation of the sample mean and variance of data. Let us see e.g., how to solve this problem using numpy. Remember, these two fundamental statistics are defined as \n",
    "\\begin{eqnarray}\n",
    "\\overline{X} &=& \\frac{1}{n}\\sum_{i=1}^n x_i, \\nonumber \\\\\n",
    "S^2 &=& \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\overline{X})^2 \\nonumber\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate random samples for which we know the true mean and variance, and \"check\" whether we get something close using the sample mean and variance. E.g., we can generate Normal distributed random numbers with prescribed mean $\\mu$ and variance $\\sigma^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of random numbers from a Gaussian distribution\n",
    "# choose parameters that are easy to visualize\n",
    "mu, sigma = 2, 0.1\n",
    "normal_data = np.random.normal(mu, sigma, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the sample mean and variance of the generated data we can use numpy's built in mean and var functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  1.993452582632089\n",
      "var = 0.010514955749002844\n",
      "sigma = 0.10254245827462322\n",
      "\n",
      "given_mean = 2\n",
      "given_var = 0.010000000000000002\n",
      "given_sigma = 0.1\n",
      "\n",
      "mean_ratio =  0.9967262913160445\n",
      "var = 1.0514955749002841\n",
      "sigma = 1.0\n"
     ]
    }
   ],
   "source": [
    "mean,var = np.mean(normal_data),np.var(normal_data);\n",
    "print('mean = ',mean)\n",
    "print('var =',var,)\n",
    "print('sigma =',math.sqrt(var))\n",
    "print()\n",
    "print('given_mean =',mu,)\n",
    "print('given_var =',sigma*sigma,)\n",
    "print('given_sigma =',sigm)\n",
    "print()\n",
    "print('mean_ratio = ',mean/mu,)\n",
    "print('var =',var/(sigma*sigma),)\n",
    "print('sigma =',sigma/sigm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  1.9999084421602542\n",
      "var = 0.00998725794893087\n",
      "sigma = 0.09993626943673088\n",
      "\n",
      "given_mean = 2\n",
      "given_var = 0.010000000000000002\n",
      "given_sigma = 0.1\n"
     ]
    }
   ],
   "source": [
    "means = []\n",
    "variances = []\n",
    "\n",
    "for i in range(1000):\n",
    "    normal_data = np.random.normal(mu, sigma, 1000)\n",
    "    mean,var = np.mean(normal_data),np.var(normal_data);\n",
    "    means.append(mean)\n",
    "    variances.append(var)\n",
    "\n",
    "meanofvalues = np.mean(means)\n",
    "meanofvariances = np.mean(variances)\n",
    "\n",
    "print('mean = ',meanofvalues)\n",
    "print('var =',meanofvariances,)\n",
    "print('sigma =',math.sqrt(meanofvariances))\n",
    "print()\n",
    "print('given_mean =',mu,)\n",
    "print('given_var =',sigma*sigma,)\n",
    "print('given_sigma =',sigm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf();\n",
    "mean_list = [np.mean(normal_data[0:i]) for i in range(2,len(normal_data)+1)];\n",
    "var_list = np.var(normal_data);\n",
    "var_alt_list = np.mean(normal_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence of the sample mean and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now examine the convergence of the sample mean and variance by plotting them as a functions of the included number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-912a92cbb426>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-912a92cbb426>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    plt.(data_size_list,mean_list,label='sample mean');\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "plt.clf();\n",
    "mean_list = [np.mean(normal_data[0:i]) for i in range(2,len(normal_data)+1)];\n",
    "var_list = np.var(normal_data);\n",
    "var_alt_list = np.mean(normal_data);\n",
    "\n",
    "data_size_list = range(2,len(mean_list)+2);\n",
    "mu_list,sigma_list = mu, sigma*sigma\n",
    "\n",
    "# plot it so, that humans can see the convergence for large values and the deviation at small values\n",
    "plt.(data_size_list,mean_list,label='sample mean');\n",
    "plt.(data_size_list,var_list,label='sample variance');\n",
    "plt.(data_size_list,mu_list,label='true mean');\n",
    "plt.(data_size_list,sigma_list,label='true variance');\n",
    "plt.(data_size_list,var_alt_list, label = 'var. MLE.');\n",
    "plt.legend(loc= 'lower right',fontsize = 10);\n",
    "plt.title('Sample mean and variance for Normal distribution')\n",
    "plt.xlabel('sample size');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's try out the same for a Pareto (Lomax) distribution as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_data = np.random.pareto(1.5,num_points); # TRY_DIFFERENT_SHAPE_PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "mean_list = [np.mean(pareto_data[0:i]) for i in range(2,len(pareto_data)+1)];\n",
    "var_list = [VARIANCE for i in range(2,len(pareto_data)+1)];\n",
    "data_size_list =range(2,len(mean_list)+2);\n",
    "\n",
    "plt.loglog(data_size_list,mean_list,label = 'sample mean');\n",
    "plt.loglog(data_size_list,var_list,label = 'sample variance');\n",
    "plt.legend(loc = 'lower left', fontsize = 10);\n",
    "plt.title('Sample mean and variance for Pareto distribution')\n",
    "plt.xlabel('sample size');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us repeat the above with data that was drawn from Cauchy distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cauchy_data = np.random.standard_cauchy(num_points);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "mean_list = [np.mean(cauchy_data[0:i]) for i in range(2,len(cauchy_data)+1)];\n",
    "var_list = [VARIANCE for i in range(2,len(cauchy_data)+1)];\n",
    "data_size_list = range(2,len(mean_list)+2);\n",
    "\n",
    "plt.plot(data_size_list,mean_list,label='sample mean');\n",
    "#plt.loglog(data_size_list,var_list,label='sample variance');\n",
    "plt.legend(loc= 'upper right',fontsize = 10);\n",
    "plt.title('Sample mean/variance for Cauchy distribution')\n",
    "plt.xlabel('sample size');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the stock market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple model of a fluctuating stock value is the following: In every time step its value is either increased by 1 cent, or is decreased by 1 cent with equal probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate this simply by drawing a random sequence of 1 and -1, and summing the obtained values. \n",
    "\n",
    "First we define the number of stocks, and the number of time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stocks = 3;\n",
    "num_time_steps = 10000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to put the generated time sequences of the stocks into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_time_series_list = [];\n",
    "stock_time_series_list.clear();\n",
    "for i in range(0,num_stocks):\n",
    "    rand_changes = list(np.random.choice([-1,1],num_time_steps)); # these are the random -1 and 1 dollars\n",
    "    stock_value = [sum(rand_changes[0:n]) for n in range(1,len(rand_changes))]; # we simply add up the first n \n",
    "    stock_time_series_list.append(stock_value);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make actually two plots: \n",
    "- first only up to the first 1000 time steps,\n",
    "- next all the way up to 10000 time steps (and highlight within the area shown in the previous figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf();\n",
    "YOUR_CODE\n",
    "plt.xlabel('time steps');\n",
    "plt.ylabel('stock value');\n",
    "plt.xlim(0,1000);\n",
    "plt.ylim(-95,95);\n",
    "plt.legend(loc= 'upper left',fontsize = 10);\n",
    "plt.show();\n",
    "\n",
    "plt.clf();\n",
    "YOUR_CODE\n",
    "plt.xlabel('time steps');\n",
    "plt.ylabel('stock value');\n",
    "plt.ylim(-300,300);\n",
    "rect = patches.Rectangle((0,-95),1000,190,edgecolor='r',facecolor='r', alpha = 0.1);\n",
    "ax.add_patch(rect);\n",
    "plt.legend(loc= 'upper left',fontsize = 10);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe that the two figures look quite similar. (More on that on the Fractals course).\n",
    "- ** What do you think, how was the vertical scale (set by ylim) chosen? **\n",
    "- Try out changing the scale of the first figure to see that it does not look similar to the 2nd if the horisontal - vertical scales are not \"properly\" set."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
